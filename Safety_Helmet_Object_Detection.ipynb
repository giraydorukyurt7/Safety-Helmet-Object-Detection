{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2               as cv\n",
    "import urllib\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from imutils        import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils  import shuffle\n",
    "from urllib.request import urlopen\n",
    "from sklearn.decomposition import PCA\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models              import Sequential\n",
    "from tensorflow.keras.preprocessing       import image\n",
    "from tensorflow.keras.utils               import to_categorical\n",
    "from tensorflow.keras.callbacks           import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers              import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img,array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-) Data Preparation\n",
    "\n",
    "Data Preprocessing + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helmet': 0, 'head': 1}\n",
      "{0: 'helmet', 1: 'head'}\n"
     ]
    }
   ],
   "source": [
    "img_folder_path = \"Dataset\\images\"\n",
    "xml_folder_path = \"Dataset\\\\annotations\"\n",
    "\n",
    "target_size = (416,416)\n",
    "\n",
    "labels_worker = {\"helmet\" : 0,\n",
    "                 \"head\"   : 1}\n",
    "\n",
    "labels_worker_reversed = {value:key for key,value in labels_worker.items()}\n",
    "print(labels_worker)\n",
    "print(labels_worker_reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(xml_folder_path, labels_dict):\n",
    "    annotations = []\n",
    "    for xml_file in os.listdir(xml_folder_path):\n",
    "        if xml_file.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(xml_folder_path, xml_file))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                \n",
    "                label = obj.find('name').text\n",
    "                if label in labels_dict:\n",
    "                    bndbox = obj.find('bndbox')\n",
    "                    xmin = int(bndbox.find('xmin').text)\n",
    "                    ymin = int(bndbox.find('ymin').text)\n",
    "                    xmax = int(bndbox.find('xmax').text)\n",
    "                    ymax = int(bndbox.find('ymax').text)\n",
    "                    annotations.append((xml_file.replace('.xml','.png'), \n",
    "                                        labels_dict[label], \n",
    "                                        xmin, \n",
    "                                        ymin, \n",
    "                                        xmax, \n",
    "                                        ymax))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(img_folder_path, annotations, target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for ann in annotations:\n",
    "        img_path = os.path.join(img_folder_path, ann[0])\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv.imread(img_path)\n",
    "            img = cv.resize(img, target_size)\n",
    "            images.append(img)\n",
    "            labels.append(ann[1:])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m annotations \u001b[38;5;241m=\u001b[39m load_annotations(xml_folder_path\u001b[38;5;241m=\u001b[39mxml_folder_path,\n\u001b[0;32m      3\u001b[0m                                labels_dict    \u001b[38;5;241m=\u001b[39mlabels_worker)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#load dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_folder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(img_folder_path, annotations, target_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_folder_path, ann[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path):\n\u001b[1;32m----> 7\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(img, target_size)\n\u001b[0;32m      9\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load annotations\n",
    "annotations = load_annotations(xml_folder_path=xml_folder_path,\n",
    "                               labels_dict    =labels_worker)\n",
    "#load dataset\n",
    "images, labels = load_dataset(img_folder_path=img_folder_path,\n",
    "                              annotations    =annotations,\n",
    "                              target_size    =target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "\n",
    "#Train set\n",
    "train_datagen = ImageDataGenerator(rescale            =1.0/255,#Normalization\n",
    "                                   zoom_range         =0.2,\n",
    "                                   width_shift_range  =0.2,\n",
    "                                   height_shift_range =0.2,\n",
    "                                   rotation_range     =40,\n",
    "                                   shear_range        =0.2,\n",
    "                                   horizontal_flip    =True,\n",
    "                                   vertical_flip      =True,\n",
    "                                   fill_mode          =\"nearest\")\n",
    "\n",
    "#Test and Val set, no augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255) #Normalizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator = train_datagen.flow(X_train,\n",
    "#                                     y_train,\n",
    "#                                     batch_size=32,\n",
    "#                                     shuffle=True,\n",
    "#                                     seed=42)\n",
    "#\n",
    "#val_generator   = test_datagen.flow (X_val,\n",
    "#                                     y_val,\n",
    "#                                     batch_size=32,\n",
    "#                                     shuffle=False,\n",
    "#                                     seed=42)\n",
    "#\n",
    "#test_generator  = test_datagen.flow (X_test,\n",
    "#                                     y_test,\n",
    "#                                     batch_size=32,\n",
    "#                                     shuffle=False,\n",
    "#                                     seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
